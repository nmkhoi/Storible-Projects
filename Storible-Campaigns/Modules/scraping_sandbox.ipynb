{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException,ElementClickInterceptedException\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "from time import sleep\n",
    "import datetime\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|██████████| 6.78M/6.78M [01:38<00:00, 72.3kB/s]\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get(\"https://www.google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitor_name</th>\n",
       "      <th>competitor_link</th>\n",
       "      <th>competitor_twitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rise at Seven</td>\n",
       "      <td>https://riseatseven.com/work/</td>\n",
       "      <td>https://twitter.com/RiseAtSeven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reboot</td>\n",
       "      <td>https://www.rebootonline.com/placements/</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kaizen</td>\n",
       "      <td>https://kaizen.co.uk/work/</td>\n",
       "      <td>https://twitter.com/kaizen_agency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Motive PR</td>\n",
       "      <td>https://www.motivepr.co.uk/work</td>\n",
       "      <td>https://twitter.com/motivepr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don't Panic</td>\n",
       "      <td>https://dontpanic.agency/</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  competitor_name                           competitor_link  \\\n",
       "0   Rise at Seven             https://riseatseven.com/work/   \n",
       "1          Reboot  https://www.rebootonline.com/placements/   \n",
       "2          Kaizen                https://kaizen.co.uk/work/   \n",
       "3       Motive PR           https://www.motivepr.co.uk/work   \n",
       "4     Don't Panic                 https://dontpanic.agency/   \n",
       "\n",
       "                  competitor_twitter  \n",
       "0    https://twitter.com/RiseAtSeven  \n",
       "1                                NaN  \n",
       "2  https://twitter.com/kaizen_agency  \n",
       "3       https://twitter.com/motivepr  \n",
       "4                                NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('../seedlist.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = 2\n",
    "\n",
    "def waiting_until_full(delay,type):\n",
    "    try:\n",
    "        element_present = EC.presence_of_all_elements_located((By.XPATH, type))\n",
    "        WebDriverWait(driver, delay).until(element_present)\n",
    "    except TimeoutException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitor_name</th>\n",
       "      <th>competitor_link</th>\n",
       "      <th>competitor_twitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rise at Seven</td>\n",
       "      <td>https://riseatseven.com/work/</td>\n",
       "      <td>https://twitter.com/RiseAtSeven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reboot</td>\n",
       "      <td>https://www.rebootonline.com/placements/</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kaizen</td>\n",
       "      <td>https://kaizen.co.uk/work/</td>\n",
       "      <td>https://twitter.com/kaizen_agency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Motive PR</td>\n",
       "      <td>https://www.motivepr.co.uk/work</td>\n",
       "      <td>https://twitter.com/motivepr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don't Panic</td>\n",
       "      <td>https://dontpanic.agency/</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Verve Search</td>\n",
       "      <td>https://www.vervesearch.com/casestudies/</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Priceonomics</td>\n",
       "      <td>https://priceonomics.com/</td>\n",
       "      <td>https://twitter.com/priceonomics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neomam</td>\n",
       "      <td>https://neomam.com/portfolio</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fractl</td>\n",
       "      <td>https://www.frac.tl/work/content-marketing-cas...</td>\n",
       "      <td>https://twitter.com/fractlagency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Digitaloft</td>\n",
       "      <td>https://digitaloft.co.uk/success-stories/</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Aira</td>\n",
       "      <td>aira.net</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Journey Further</td>\n",
       "      <td>https://www.journeyfurther.com/</td>\n",
       "      <td>https://twitter.com/journeyfurther</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>JBH</td>\n",
       "      <td>https://jbh.co.uk/</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Yard</td>\n",
       "      <td>https://weareyard.com/case-studies/service/dig...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    competitor_name                                    competitor_link  \\\n",
       "0     Rise at Seven                      https://riseatseven.com/work/   \n",
       "1            Reboot           https://www.rebootonline.com/placements/   \n",
       "2            Kaizen                         https://kaizen.co.uk/work/   \n",
       "3         Motive PR                    https://www.motivepr.co.uk/work   \n",
       "4       Don't Panic                          https://dontpanic.agency/   \n",
       "5      Verve Search           https://www.vervesearch.com/casestudies/   \n",
       "6      Priceonomics                          https://priceonomics.com/   \n",
       "7            Neomam                       https://neomam.com/portfolio   \n",
       "8            Fractl  https://www.frac.tl/work/content-marketing-cas...   \n",
       "9        Digitaloft          https://digitaloft.co.uk/success-stories/   \n",
       "10             Aira                                           aira.net   \n",
       "11  Journey Further                    https://www.journeyfurther.com/   \n",
       "12              JBH                                 https://jbh.co.uk/   \n",
       "13             Yard  https://weareyard.com/case-studies/service/dig...   \n",
       "\n",
       "                    competitor_twitter  \n",
       "0      https://twitter.com/RiseAtSeven  \n",
       "1                                  NaN  \n",
       "2    https://twitter.com/kaizen_agency  \n",
       "3         https://twitter.com/motivepr  \n",
       "4                                  NaN  \n",
       "5                                  NaN  \n",
       "6     https://twitter.com/priceonomics  \n",
       "7                                  NaN  \n",
       "8     https://twitter.com/fractlagency  \n",
       "9                                  NaN  \n",
       "10                                 NaN  \n",
       "11  https://twitter.com/journeyfurther  \n",
       "12                                 NaN  \n",
       "13                                 NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seedlist_competitor = pd.read_excel('seedlist.xlsx','competitors')\n",
    "seedlist_competitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_link</th>\n",
       "      <th>client_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.electronicshub.org/insights/</td>\n",
       "      <td>electronicshub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.budgetdirect.com.au/</td>\n",
       "      <td>budgetdirect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.poundstopocket.co.uk/</td>\n",
       "      <td>poundstopocket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.homeadvisor.com/</td>\n",
       "      <td>homeadvisor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.angi.com/</td>\n",
       "      <td>angi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                client_link     client_name\n",
       "0  https://www.electronicshub.org/insights/  electronicshub\n",
       "1          https://www.budgetdirect.com.au/    budgetdirect\n",
       "2         https://www.poundstopocket.co.uk/  poundstopocket\n",
       "3              https://www.homeadvisor.com/     homeadvisor\n",
       "4                     https://www.angi.com/            angi"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seedlist_client = pd.read_excel('seedlist.xlsx','clients')\n",
    "seedlist_client.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#riseatseven\n",
    "\n",
    "def riseatseven():\n",
    "    pr_camps = pd.DataFrame(columns=['Name', 'Link', 'Source', 'Published Date'])\n",
    "\n",
    "    for comp_link in seedlist_competitor['competitor_link']:\n",
    "        if 'riseatseven' in comp_link:\n",
    "            try:\n",
    "                driver.get(comp_link)\n",
    "                waiting_until_full(delay, '//*[@id=\"gatsby-focus-wrapper\"]/main/div[5]/div[4]')\n",
    "                digital_pr = driver.find_element(By.XPATH, '//*[@id=\"gatsby-focus-wrapper\"]/main/div[5]/div[4]')\n",
    "                lists = digital_pr.find_elements(By.TAG_NAME,'a')\n",
    "                links = [lists[i].get_attribute('href') for i in range(len(lists))]\n",
    "                for link in links:\n",
    "                    driver.get(link)\n",
    "                    waiting_until_full(delay, '/html/body')\n",
    "                    sleep(2)\n",
    "                    names = driver.find_element(By.XPATH,'//*[@id=\"gatsby-focus-wrapper\"]/main/div[1]/div[2]/div[1]/div/div/div/div/h3[2]').text\n",
    "                    text = driver.find_element(By.XPATH, '//*[@id=\"gatsby-focus-wrapper\"]/main/div[3]/div/div[3]/div')\n",
    "                    total_links_xpath = text.find_elements(By.TAG_NAME, 'a')\n",
    "                    total_links =  list({total_links_xpath[i].get_attribute('href') for i in range(len(total_links_xpath))})\n",
    "                    p_date = driver.find_element(By.XPATH, '//*[@id=\"gatsby-focus-wrapper\"]/main/div[3]/div/div[1]/div/div[3]/h4').text\n",
    "                    url = driver.current_url\n",
    "                    # ex_link = [l for l in total_links if 'weareyard' not in l]\n",
    "                    links_final = [l for l in total_links if 'riseatseven' not in l]\n",
    "                    pr_camps = pd.concat([pr_camps, pd.DataFrame.from_records([{'Name': names, 'Link': links_final, 'Source': url, 'Published Date': p_date}])])\n",
    "                    sleep(2)\n",
    "\n",
    "                print(\"Riseatseven's total campaigns are: {}\".format(len(pr_camps)))\n",
    "                # df = pd.DataFrame(list(pr_camps.items()),columns=['Name','Links'])\n",
    "                # df['source'] = 'riseatseven'\n",
    "                pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace('[',''))\n",
    "                pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(']',''))\n",
    "                pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(\"'\",''))\n",
    "            except Exception as e:\n",
    "                # pr_camps = pd.DataFrame()\n",
    "                continue\n",
    "    return pr_camps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reboot\n",
    "def reboot():\n",
    "    pr_camps = pd.DataFrame(columns=['Name', 'Link', 'Source', 'Published Date'])\n",
    "\n",
    "    for comp_link in seedlist_competitor['competitor_link']:\n",
    "        if 'reboot' in comp_link:\n",
    "            try:\n",
    "                driver.get(comp_link)\n",
    "                waiting_until_full(delay, '/html/body/script[2]')\n",
    "                json_raw = json.loads(driver.find_element(By.XPATH, '/html/body/script[2]').get_attribute('innerHTML')[15:-1])\n",
    "                for i in json_raw:\n",
    "                    for j in range(len(i['list'])):\n",
    "                        name = i['list'][j]['campaign']['name'].title()\n",
    "                        link = i['list'][j]['url_link']\n",
    "                        source = driver.current_url\n",
    "                        p_date = i['list'][j]['campaign']['start_date']\n",
    "                # pr_camps = {i['list'][j]['campaign']['name'].title(): i['list'][j]['url_link'] for i in json_raw for j in range(len(i['list']))}\n",
    "                        pr_camps = pd.concat([pr_camps, pd.DataFrame.from_records([{'Name': name, 'Link': link, 'Source': source, 'Published Date': p_date}])])\n",
    "                print(\"Rebootonline's total campaigns are: {}\".format(len(pr_camps)))\n",
    "            except Exception as e:\n",
    "                print('1')\n",
    "                # pr_camps = {}\n",
    "                continue\n",
    "            # df = pd.DataFrame(list(pr_camps.items()),columns=['Name','Links'])\n",
    "            pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace('[',''))\n",
    "            pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(']',''))\n",
    "            pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(\"'\",''))\n",
    "    return pr_camps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#motivepr\n",
    "def motivepr():\n",
    "    pr_camps = pd.DataFrame(columns=['Name', 'Link', 'Source', 'Published Date'])\n",
    "\n",
    "    for comp_link in seedlist_competitor['competitor_link']:\n",
    "        if 'motivepr' in comp_link:\n",
    "            try:\n",
    "                driver.get(comp_link)\n",
    "                waiting_until_full(delay, '/html/body/div[5]')\n",
    "                sleep(2)\n",
    "                digital_pr = driver.find_element(By.XPATH, '/html/body/div[5]/div/div')\n",
    "                lists = digital_pr.find_elements(By.TAG_NAME,'a')\n",
    "                links = [lists[i].get_attribute('href') for i in range(len(lists))]\n",
    "                for link in links:\n",
    "                    driver.get(link)\n",
    "                    waiting_until_full(delay, '//*[@id=\"content\"]/section[2]')\n",
    "                    sleep(2)\n",
    "                    names = driver.find_element(By.TAG_NAME,'h1').text\n",
    "                    source = driver.current_url\n",
    "                    p_date = 'unavailable'\n",
    "                    text = driver.find_element(By.XPATH, '/html/body/div[11]/div/div/div[1]')\n",
    "                    total_links_xpath = text.find_elements(By.TAG_NAME, 'a')\n",
    "                    total_links =  list({total_links_xpath[i].get_attribute('href') for i in range(len(total_links_xpath))})\n",
    "                    links_final = [l for l in total_links if 'motivepr' not in l]\n",
    "                    pr_camps = pd.concat([pr_camps, pd.DataFrame.from_records([{'Name': names, 'Link': links_final, 'Source': source, 'Published Date': p_date}])])\n",
    "                    sleep(2)\n",
    "                driver.back()\n",
    "                sleep(2)\n",
    "                print(\"MotivePR's total campaigns: {}\".format(len(pr_camps)))\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "    # df = pd.DataFrame(list(pr_camps.items()),columns=['Name','Links'])\n",
    "    # df['source'] = 'motivepr'\n",
    "    pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace('[',''))\n",
    "    pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(']',''))\n",
    "    pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(\"'\",''))\n",
    "            # print(df)\n",
    "    return pr_camps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dontpanic\n",
    "def dontpanic():\n",
    "    pr_camps = pd.DataFrame(columns=['Name', 'Link', 'Source', 'Published Date'])\n",
    "\n",
    "    for comp_link in seedlist_competitor['competitor_link']:\n",
    "        if 'dontpanic' in comp_link:\n",
    "            driver.get(comp_link)\n",
    "            waiting_until_full(delay, '//*[@id=\"work_items\"]')\n",
    "            digital_pr = driver.find_element(By.XPATH, '//*[@id=\"work_items\"]')\n",
    "            camps = [camp.get_attribute('href') for camp in digital_pr.find_elements(By.TAG_NAME, 'a')]\n",
    "            try:\n",
    "                for i in camps:\n",
    "                    driver.get(i)\n",
    "                    waiting_until_full(delay, '//*[@id=\"new_page_holder_inner\"]/div/div[1]/div[1]')\n",
    "                    sleep(10)\n",
    "                    name = driver.find_element(By.TAG_NAME, 'h1').text\n",
    "                    links = driver.find_element(By.CLASS_NAME,'link').find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                    source = driver.current_url\n",
    "                    p_date = 'unavailable'\n",
    "                    pr_camps = pd.concat([pr_camps, pd.DataFrame.from_records([{'Name': name, 'Link': links, 'Source': source, 'Published Date': p_date}])])\n",
    "                    driver.back()\n",
    "                    waiting_until_full(delay, '//*[@id=\"work_items\"]')\n",
    "                    sleep(10)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    print(\"Dontpanic's total campaigns are: {}\".format(len(pr_camps)))\n",
    "    pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace('[',''))\n",
    "    pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(']',''))\n",
    "    pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(\"'\",''))\n",
    "    return pr_camps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vervesearch\n",
    "def vervesearch():\n",
    "    pr_camps = pd.DataFrame(columns=['Name', 'Link', 'Source', 'Published Date'])\n",
    "\n",
    "    for comp_link in seedlist_competitor['competitor_link']:\n",
    "        if 'vervesearch' in comp_link:\n",
    "            driver.get(comp_link)\n",
    "            waiting_until_full(delay, '/html/body/main/section[1]/div/ul')\n",
    "            digital_pr = driver.find_element(By.XPATH, '/html/body/main/section[1]/div/ul')\n",
    "            camps = [camp.get_attribute('href') for camp in digital_pr.find_elements(By.TAG_NAME, 'a')]\n",
    "            try:\n",
    "                for camp in camps:\n",
    "                    names = camp.split('/')[-2].replace('-',' ').title()\n",
    "                    driver.get(camp)\n",
    "                    waiting_until_full(delay, '/html/body/main/section[2]/div/a')\n",
    "                    link = driver.find_elements(By.CLASS_NAME, 'button')[0].get_attribute('href')\n",
    "                    source = camp\n",
    "                    p_date = 'unavailable'\n",
    "                    pr_camps = pd.concat([pr_camps, pd.DataFrame.from_records([{'Name': names, 'Link': link, 'Source': source, 'Published Date': p_date}])])\n",
    "                    driver.back()\n",
    "                    waiting_until_full(delay, '/html/body/main/section[1]/div/ul')\n",
    "                    sleep(3)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    print(\"Vervesearch's total campaigns are: {}\".format(len(pr_camps)))\n",
    "    pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace('[',''))\n",
    "    pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(']',''))\n",
    "    pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(\"'\",''))\n",
    "    return pr_camps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neomam\n",
    "def neomam():\n",
    "    pr_camps = pd.DataFrame(columns=['Name', 'Link', 'Source', 'Published Date'])\n",
    "\n",
    "    for comp_link in seedlist_competitor['competitor_link']:\n",
    "        if 'neomam' in comp_link:\n",
    "            try:\n",
    "                driver.get(comp_link)\n",
    "                waiting_until_full(delay, '//*[@id=\"__layout\"]/div/div/div[2]')\n",
    "                for i in range(10):\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    sleep(2)\n",
    "                waiting_until_full(delay, '//*[@id=\"__layout\"]/div/div/div[2]')\n",
    "                sleep(2)\n",
    "                digital_pr = driver.find_elements(By.LINK_TEXT,'see it live')\n",
    "                for i, camp in enumerate(digital_pr):\n",
    "                    camps = camp.get_attribute('href')\n",
    "                    names = driver.find_element(By.XPATH, '//*[@id=\"__layout\"]/div/div/div[2]/div/div[{}]/div[2]/p[1]/b'.format(i+1)).text\n",
    "                    source = driver.current_url\n",
    "                    p_date = 'unavailable'\n",
    "                    pr_camps = pd.concat([pr_camps, pd.DataFrame.from_records([{'Name': names, 'Link': camps, 'Source': source, 'Published Date': p_date}])])\n",
    "                print(\"Neomam's total campaigns: {}\".format(len(pr_camps)))\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "            pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace('[',''))\n",
    "            pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(']',''))\n",
    "            pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(\"'\",''))\n",
    "    return pr_camps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fractl\n",
    "def fractl():\n",
    "    pr_camps = {}\n",
    "\n",
    "    for comp_link in seedlist_competitor['competitor_link']:\n",
    "        if 'frac' in comp_link:\n",
    "            try:\n",
    "                driver.get(comp_link)\n",
    "                waiting_until_full(delay, '/html/body/section[2]/div')\n",
    "                sleep(2)\n",
    "                pr_camps = driver.find_element(By.XPATH,'/html/body/section[2]/div')\n",
    "                all_links = pr_camps.find_elements(By.TAG_NAME, 'a')\n",
    "                links = list({link.get_attribute('href') for link in all_links})\n",
    "                for link in links:\n",
    "                    driver.get(link)\n",
    "                    waiting_until_full(delay, '/html/body')\n",
    "                    sleep(2)\n",
    "                    names = driver.find_element(By.TAG_NAME,'h1').text\n",
    "                    text = driver.find_element(By.XPATH, '/html/body')\n",
    "                    total_links_xpath = text.find_elements(By.TAG_NAME, 'a')\n",
    "                    total_links =  list({total_links_xpath[i].get_attribute('href') for i in range(len(total_links_xpath))})\n",
    "                    # ex_link = [l for l in total_links if 'weareyard' not in l]\n",
    "                    pr_camps[names] = [l for l in total_links if 'frac' not in l]\n",
    "                    sleep(2)\n",
    "                driver.back()\n",
    "                sleep(2)\n",
    "                print(\"Fractl's total campaigns: {}\".format(len(pr_camps)))\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    df = pd.DataFrame(list(pr_camps.items()),columns=['Name','Links'])\n",
    "    df['source'] = 'fractl'\n",
    "    df['Links'] = df['Links'].map(lambda x: str(x).replace('[',''))\n",
    "    df['Links'] = df['Links'].map(lambda x: str(x).replace(']',''))\n",
    "    df['Links'] = df['Links'].map(lambda x: str(x).replace(\"'\",''))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#digitaloft\n",
    "def digitaloft():\n",
    "    pr_camps = pd.DataFrame(columns=['Name', 'Link', 'Source', 'Published Date'])\n",
    "    \n",
    "    for comp_link in seedlist_competitor['competitor_link']:\n",
    "        if 'digitaloft' in comp_link:\n",
    "            try:\n",
    "                driver.get(comp_link)\n",
    "                waiting_until_full(delay, '//*[@id=\"page\"]/div[4]/div/div')\n",
    "                sleep(2)\n",
    "                digital_pr = driver.find_element(By.XPATH,'//*[@id=\"page\"]/div[4]/div/div')\n",
    "                camps = digital_pr.find_elements(By.TAG_NAME, 'a')\n",
    "                links = list({camp.get_attribute('href') for camp in camps})\n",
    "                names = [link.split('/')[-2].replace('-',' ').title() for link in links]\n",
    "                pr_camps = {names[i]: links[i] for i in range(len(names))}\n",
    "                print(\"Digitaloft's total campaigns: {}\".format(len(pr_camps)))\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "            df = pd.DataFrame(list(pr_camps.items()),columns=['Name','Links'])\n",
    "            df['source'] = 'https://digitaloft.co.uk/success-stories/'\n",
    "            df['Publish Date'] = 'unavailable'\n",
    "            df['Links'] = df['Links'].map(lambda x: str(x).replace('[',''))\n",
    "            df['Links'] = df['Links'].map(lambda x: str(x).replace(']',''))\n",
    "            df['Links'] = df['Links'].map(lambda x: str(x).replace(\"'\",''))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weareyard\n",
    "def weareyard():\n",
    "    pr_camps = pd.DataFrame(columns=['Name', 'Link', 'Source', 'Published Date'])\n",
    "\n",
    "    for comp_link in seedlist_competitor['competitor_link']:\n",
    "        if 'weareyard' in comp_link:\n",
    "            try:\n",
    "                driver.get(comp_link)\n",
    "                waiting_until_full(delay, '//*[@id=\"content\"]')\n",
    "                sleep(2)\n",
    "                digital_pr = driver.find_elements(By.CLASS_NAME, 'casestudy_content')\n",
    "                links = [digital_pr[i].find_element(By.TAG_NAME,'a').get_attribute('href') for i in range(len(digital_pr))]\n",
    "                # names = [digital_pr[i].find_element(By.TAG_NAME,'h3').text for i in range(len(digital_pr))]\n",
    "                for link in links:\n",
    "                    driver.get(link)\n",
    "                    waiting_until_full(delay, '//*[@id=\"content\"]/section[2]')\n",
    "                    sleep(2)\n",
    "                    names = driver.find_element(By.TAG_NAME,'h1').text\n",
    "                    text = driver.find_element(By.XPATH, '//*[@id=\"content\"]/section[2]')\n",
    "                    total_links_xpath = text.find_elements(By.TAG_NAME, 'a')\n",
    "                    total_links =  list({total_links_xpath[i].get_attribute('href') for i in range(len(total_links_xpath))})\n",
    "                    # ex_link = [l for l in total_links if 'weareyard' not in l]\n",
    "                    links_final = [l for l in total_links if 'weareyard' not in l]\n",
    "                    source = driver.current_url\n",
    "                    p_date = 'unavailable'\n",
    "                    pr_camps = pd.concat([pr_camps, pd.DataFrame.from_records([{'Name': names, 'Link': links_final, 'Source': source, 'Published Date': p_date}])])\n",
    "                    sleep(2)\n",
    "                driver.back()\n",
    "                sleep(2)\n",
    "                print(\"Weareyard's total campaigns: {}\".format(len(pr_camps)))\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "    pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace('[',''))\n",
    "    pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(']',''))\n",
    "    pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(\"'\",''))\n",
    "    return pr_camps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weareyard's total campaigns: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Link</th>\n",
       "      <th>Source</th>\n",
       "      <th>Published Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Building brand with a viral digital PR campaign</td>\n",
       "      <td>https://weareyard.com/case-studies/yard-celeb-...</td>\n",
       "      <td>https://weareyard.com/case-studies/yard-celeb-...</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Demonstrating digital PR creativity for VisitS...</td>\n",
       "      <td>https://weareyard.com/case-studies/visitscotla...</td>\n",
       "      <td>https://weareyard.com/case-studies/visitscotla...</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Creating captivating campaigns for Wealthify</td>\n",
       "      <td>https://weareyard.com/case-studies/wealthify</td>\n",
       "      <td>https://weareyard.com/case-studies/wealthify</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0    Building brand with a viral digital PR campaign   \n",
       "0  Demonstrating digital PR creativity for VisitS...   \n",
       "0       Creating captivating campaigns for Wealthify   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://weareyard.com/case-studies/yard-celeb-...   \n",
       "0  https://weareyard.com/case-studies/visitscotla...   \n",
       "0       https://weareyard.com/case-studies/wealthify   \n",
       "\n",
       "                                              Source Published Date  \n",
       "0  https://weareyard.com/case-studies/yard-celeb-...    unavailable  \n",
       "0  https://weareyard.com/case-studies/visitscotla...    unavailable  \n",
       "0       https://weareyard.com/case-studies/wealthify    unavailable  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weareyard()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#electronicshub\n",
    "\n",
    "def electronicshub():\n",
    "    pr_camps = pd.DataFrame(columns=['Name', 'Link', 'Source', 'Published Date'])\n",
    "\n",
    "    for client_link in seedlist_client['client_link']:\n",
    "        if 'electronicshub' in client_link:\n",
    "            try:\n",
    "                driver.get(client_link)\n",
    "                waiting_until_full(delay, '/html/body/div[1]/section[2]/div/div[1]')\n",
    "                digital_pr = driver.find_element(By.XPATH, '/html/body/div/section[2]/div/div[1]/div/div[1]/div')\n",
    "                a_ids = digital_pr.find_elements(By.TAG_NAME, 'article')\n",
    "                list_id = [id.get_attribute('id') for id in a_ids]\n",
    "                lists = digital_pr.find_elements(By.TAG_NAME,'a')\n",
    "                for i in range(len(lists)):\n",
    "                    links = driver.find_element(By.XPATH, '//*[@id=\"{}\"]/div/section/div/div[2]/div/div[2]/div/h2/a'.format(list_id[i])).get_attribute('href')\n",
    "                    names = driver.find_element(By.XPATH, '//*[@id=\"{}\"]/div/section/div/div[2]/div/div[2]/div/h2/a'.format(list_id[i])).text\n",
    "                    source = driver.current_url\n",
    "                    p_date = driver.find_element(By.XPATH, '//*[@id=\"{}\"]/div/section/div/div[2]/div/div[4]/div/ul/li/span'.format(list_id[i])).text\n",
    "                    pr_camps = pd.concat([pr_camps, pd.DataFrame.from_records([{'Name': names, 'Link': links, 'Source': source, 'Published Date': p_date}])])\n",
    "                print(\"electronicshub's total campaigns are: {}\".format(len(pr_camps)))\n",
    "                # df = pd.DataFrame(list(pr_camps.items()),columns=['Name','Links'])\n",
    "                # df['source'] = 'https://www.electronicshub.org/insights/'\n",
    "                pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace('[',''))\n",
    "                pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(']',''))\n",
    "                pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(\"'\",''))\n",
    "                # pr_camps = pr_camps.iloc[2:,:]\n",
    "            except Exception as e:\n",
    "                continue \n",
    "    return pr_camps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#budgetdirect\n",
    "\n",
    "def budgetdirect():\n",
    "    pr_camps = {}\n",
    "\n",
    "    for client_link in seedlist_client['client_link']:\n",
    "        if 'budgetdirect' in client_link:\n",
    "            try:\n",
    "                main_links = ['https://www.budgetdirect.com.au/car-insurance/articles.html', 'https://www.budgetdirect.com.au/travel-insurance/articles.html',\n",
    "                        'https://www.budgetdirect.com.au/home-contents-insurance/articles.html', 'https://www.budgetdirect.com.au/life-insurance/articles.html']\n",
    "                for main_link in main_links:\n",
    "                    driver.get(main_link)\n",
    "                    waiting_until_full(delay, '/html/body/div[4]/div[2]/div/div/div/div/div/div/div/div/div')\n",
    "                    digital_pr = driver.find_element(By.XPATH, '/html/body/div[4]/div[2]/div/div/div/div/div/div/div/div/div')\n",
    "                    lists = digital_pr.find_elements(By.TAG_NAME,'a')\n",
    "                    links = [link.get_attribute('href') for link in lists if link.get_attribute('class') == 'column__link']                  \n",
    "                    texts = digital_pr.find_elements(By.TAG_NAME, 'h3')\n",
    "                    names = [text.text for text in texts]\n",
    "                    pr_camps = {names[i]: links[i] for i in range(len(links))}\n",
    "                    print(\"budgetdirect's total campaigns are: {}\".format(len(pr_camps)))\n",
    "                    df = pd.DataFrame(list(pr_camps.items()),columns=['Name','Link'])\n",
    "\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    df['Source'] = 'https://www.budgetdirect.com.au/'\n",
    "    df['Published Date'] = 'unavailable'\n",
    "    df['Link'] = df['Link'].map(lambda x: str(x).replace('[',''))\n",
    "    df['Link'] = df['Link'].map(lambda x: str(x).replace(']',''))\n",
    "    df['Link'] = df['Link'].map(lambda x: str(x).replace(\"'\",''))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#businessbacker\n",
    "\n",
    "def businessbacker():\n",
    "    pr_camps = pd.DataFrame(columns=['Name', 'Link', 'Source', 'Published Date'])\n",
    "\n",
    "    for client_link in seedlist_client['client_link']:\n",
    "        if 'businessbacker' in client_link:\n",
    "            try:\n",
    "                for i in range(1,22):\n",
    "                    driver.get(client_link + 'page/{}/'.format(i))\n",
    "                    waiting_until_full(delay, '/html/body/div[2]/main/section[4]/div/div[1]/div[1]/div')\n",
    "                    sleep(5)\n",
    "                    digital_pr = driver.find_element(By.XPATH, '/html/body/div[2]/main/section[4]/div/div[1]/div[1]/div')\n",
    "                    source = driver.current_url\n",
    "                    for j in range(1,11):\n",
    "                        links = driver.find_element(By.XPATH, '/html/body/div[2]/main/section[4]/div/div[1]/div[1]/div/div[{}]/div/p/a'.format(j)).get_attribute('href')\n",
    "                        names = driver.find_element(By.XPATH, '/html/body/div[2]/main/section[4]/div/div[1]/div[1]/div/div[{}]/div/p/a'.format(j)).text\n",
    "                        p_date =  driver.find_element(By.XPATH, '/html/body/div[2]/main/section[4]/div/div[1]/div[1]/div/div[{}]/div/time'.format(j)).text\n",
    "                        pr_camps = pd.concat([pr_camps, pd.DataFrame.from_records([{'Name': names, 'Link': links, 'Source': source, 'Published Date': p_date}])])\n",
    "                    # main_df = main_df.append(df, ignore_index=True)\n",
    "                print(\"businessbacker's total campaigns are: {}\".format(len(pr_camps)))\n",
    "                pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace('[',''))\n",
    "                pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(']',''))\n",
    "                pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(\"'\",''))\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    return  pr_camps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Link</th>\n",
       "      <th>Source</th>\n",
       "      <th>Published Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What Is Loan Stacking?</td>\n",
       "      <td>https://www.businessbacker.com/blog/what-is-lo...</td>\n",
       "      <td>https://www.businessbacker.com/blog/most-recent/</td>\n",
       "      <td>October 10, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What To Do if Your Application Is Declined</td>\n",
       "      <td>https://www.businessbacker.com/blog/applicatio...</td>\n",
       "      <td>https://www.businessbacker.com/blog/most-recent/</td>\n",
       "      <td>August 25, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 Ways Multiple Financing Options Can Help Gro...</td>\n",
       "      <td>https://www.businessbacker.com/blog/financing-...</td>\n",
       "      <td>https://www.businessbacker.com/blog/most-recent/</td>\n",
       "      <td>August 18, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Dispute Errors on Your Credit Report</td>\n",
       "      <td>https://www.businessbacker.com/blog/dispute-er...</td>\n",
       "      <td>https://www.businessbacker.com/blog/most-recent/</td>\n",
       "      <td>June 15, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does Cash Flow Affect My Business Loan Applica...</td>\n",
       "      <td>https://www.businessbacker.com/blog/does-cash-...</td>\n",
       "      <td>https://www.businessbacker.com/blog/most-recent/</td>\n",
       "      <td>April 6, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quick Loans Can Help Your Business Find the Ca...</td>\n",
       "      <td>https://www.businessbacker.com/blog/quick-loan...</td>\n",
       "      <td>https://www.businessbacker.com/blog/most-recen...</td>\n",
       "      <td>October 15, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What Small Business Loans Best Suit Your Company?</td>\n",
       "      <td>https://www.businessbacker.com/blog/best-small...</td>\n",
       "      <td>https://www.businessbacker.com/blog/most-recen...</td>\n",
       "      <td>October 8, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Become a Restaurateur!</td>\n",
       "      <td>https://www.businessbacker.com/blog/how-to-bec...</td>\n",
       "      <td>https://www.businessbacker.com/blog/most-recen...</td>\n",
       "      <td>October 7, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don’t Hire A Business Coach Who Can’t Answer T...</td>\n",
       "      <td>https://www.businessbacker.com/blog/dont-hire-...</td>\n",
       "      <td>https://www.businessbacker.com/blog/most-recen...</td>\n",
       "      <td>October 1, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Cost of Going Green Globally</td>\n",
       "      <td>https://www.businessbacker.com/blog/cost-going...</td>\n",
       "      <td>https://www.businessbacker.com/blog/most-recen...</td>\n",
       "      <td>September 3, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  \\\n",
       "0                              What Is Loan Stacking?   \n",
       "0          What To Do if Your Application Is Declined   \n",
       "0   4 Ways Multiple Financing Options Can Help Gro...   \n",
       "0         How to Dispute Errors on Your Credit Report   \n",
       "0   Does Cash Flow Affect My Business Loan Applica...   \n",
       "..                                                ...   \n",
       "0   Quick Loans Can Help Your Business Find the Ca...   \n",
       "0   What Small Business Loans Best Suit Your Company?   \n",
       "0                       How to Become a Restaurateur!   \n",
       "0   Don’t Hire A Business Coach Who Can’t Answer T...   \n",
       "0                    The Cost of Going Green Globally   \n",
       "\n",
       "                                                 Link  \\\n",
       "0   https://www.businessbacker.com/blog/what-is-lo...   \n",
       "0   https://www.businessbacker.com/blog/applicatio...   \n",
       "0   https://www.businessbacker.com/blog/financing-...   \n",
       "0   https://www.businessbacker.com/blog/dispute-er...   \n",
       "0   https://www.businessbacker.com/blog/does-cash-...   \n",
       "..                                                ...   \n",
       "0   https://www.businessbacker.com/blog/quick-loan...   \n",
       "0   https://www.businessbacker.com/blog/best-small...   \n",
       "0   https://www.businessbacker.com/blog/how-to-bec...   \n",
       "0   https://www.businessbacker.com/blog/dont-hire-...   \n",
       "0   https://www.businessbacker.com/blog/cost-going...   \n",
       "\n",
       "                                               Source     Published Date  \n",
       "0    https://www.businessbacker.com/blog/most-recent/   October 10, 2022  \n",
       "0    https://www.businessbacker.com/blog/most-recent/    August 25, 2022  \n",
       "0    https://www.businessbacker.com/blog/most-recent/    August 18, 2022  \n",
       "0    https://www.businessbacker.com/blog/most-recent/      June 15, 2022  \n",
       "0    https://www.businessbacker.com/blog/most-recent/      April 6, 2022  \n",
       "..                                                ...                ...  \n",
       "0   https://www.businessbacker.com/blog/most-recen...   October 15, 2013  \n",
       "0   https://www.businessbacker.com/blog/most-recen...    October 8, 2013  \n",
       "0   https://www.businessbacker.com/blog/most-recen...    October 7, 2013  \n",
       "0   https://www.businessbacker.com/blog/most-recen...    October 1, 2013  \n",
       "0   https://www.businessbacker.com/blog/most-recen...  September 3, 2013  \n",
       "\n",
       "[205 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "businessbacker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expedia\n",
    "# need fixing\n",
    "def expedia():\n",
    "    pr_camps = {}\n",
    "    c = 0\n",
    "    for client_link in seedlist_client['client_link']:\n",
    "        if 'expedia' in client_link:\n",
    "            try:\n",
    "                driver.get(client_link)\n",
    "                waiting_until_full(delay, '//*[@id=\"ag-main\"]/div/div[4]')\n",
    "                digital_pr = driver.find_element(By.XPATH, '//*[@id=\"ag-main\"]/div/div[4]')\n",
    "                button = digital_pr.find_element(By.XPATH, '//*[@id=\"ag-main\"]/div/div[4]/button')\n",
    "                while c <= 20:\n",
    "                    button.click()\n",
    "                    sleep(delay)\n",
    "                    c += 1\n",
    "                lists = digital_pr.find_elements(By.TAG_NAME,'a')\n",
    "                links = [link.get_attribute('href') for link in lists]\n",
    "                texts = digital_pr.find_elements(By.CLASS_NAME, 'ag-archive-post-title')\n",
    "                names = [text.text for text in texts]\n",
    "                pr_camps = {names[i]: links[i] for i in range(len(links))}\n",
    "                print(\"expedia's total campaigns are: {}\".format(len(pr_camps)))\n",
    "                df = pd.DataFrame(list(pr_camps.items()),columns=['Name','Links'])\n",
    "                df['source'] = 'expedia'\n",
    "                df['Links'] = df['Links'].map(lambda x: str(x).replace('[',''))\n",
    "                df['Links'] = df['Links'].map(lambda x: str(x).replace(']',''))\n",
    "                df['Links'] = df['Links'].map(lambda x: str(x).replace(\"'\",''))\n",
    "            except Exception as e:\n",
    "                continue \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#homes\n",
    "\n",
    "def homes():\n",
    "    pr_camps = pd.DataFrame(columns=['Name', 'Link', 'Source', 'Published Date'])\n",
    "\n",
    "    for client_link in seedlist_client['client_link']:\n",
    "        if 'homes.com' in client_link:\n",
    "            try:\n",
    "                for i in range(1,21):\n",
    "                    driver.get(client_link + 'page/{}/'.format(i))\n",
    "                    waiting_until_full(delay, '//*[@id=\"primary\"]/div[2]/div')\n",
    "                    sleep(5)\n",
    "                    posts = driver.find_elements(By.TAG_NAME, 'article')\n",
    "                    post_ids = [id.get_attribute('id') for id in posts]\n",
    "                    source = driver.current_url\n",
    "                    for post in post_ids:\n",
    "                        links = driver.find_element(By.XPATH, '//*[@id=\"{}\"]/div/div[1]/a'.format(post)).get_attribute('href')\n",
    "                        names = driver.find_element(By.XPATH, '//*[@id=\"{}\"]/div/div[1]/a/h2'.format(post)).text\n",
    "                        p_date = driver.find_element(By.XPATH, '//*[@id=\"{}\"]/div/div[2]/span[2]'.format(post)).text\n",
    "                        pr_camps = pd.concat([pr_camps, pd.DataFrame.from_records([{'Name': names, 'Link': links, 'Source': source, 'Published Date': p_date}])])\n",
    "                    # main_df = main_df.append(df, ignore_index=True)\n",
    "                print(\"homes's total campaigns are: {}\".format(len(pr_camps)))\n",
    "                pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace('[',''))\n",
    "                pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(']',''))\n",
    "                pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(\"'\",''))\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    return  pr_camps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#surfshark\n",
    "\n",
    "def surfshark():\n",
    "    pr_camps = pd.DataFrame(columns=['Name', 'Link', 'Source', 'Published Date'])\n",
    "    for client_link in seedlist_client['client_link']:\n",
    "        if 'surfshark' in client_link:\n",
    "            try:\n",
    "                for i in range(1,6):\n",
    "                    if i == 1:\n",
    "                        driver.get(client_link)\n",
    "                        waiting_until_full(delay, '//*[@id=\"__next\"]/div/main/div[2]/div[2]/div')\n",
    "                        sleep(5)\n",
    "                        source = driver.current_url\n",
    "                        for j in range(1,7):\n",
    "                            names = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div/main/div[2]/div[2]/div/div[{}]/a/div/h3'.format(j)).text                                   \n",
    "                            links = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div/main/div[2]/div[2]/div/div[{}]/a'.format(j)).get_attribute('href')\n",
    "                            p_date = 'unavailable'\n",
    "                            pr_camps = pd.concat([pr_camps, pd.DataFrame.from_records([{'Name': names, 'Link': links, 'Source': source, 'Published Date': p_date}])])\n",
    "                    else:\n",
    "                        driver.get(client_link + '/{}'.format(i))\n",
    "                        waiting_until_full(delay, '//*[@id=\"__next\"]/div/main/div[2]/div/div')\n",
    "                        sleep(5)\n",
    "                        for j in range(1,7):\n",
    "                            names = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div/main/div[2]/div/div/div[{}]/a/div/h3'.format(j)).text\n",
    "                            links = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div/main/div[2]/div/div/div[{}]/a'.format(j)).get_attribute('href')\n",
    "                            p_date = 'unavailable'\n",
    "                            pr_camps = pd.concat([pr_camps, pd.DataFrame.from_records([{'Name': names, 'Link': links, 'Source': source, 'Published Date': p_date}])])\n",
    "                    waiting_until_full(delay, '//*[@id=\"__next\"]/div/main/div[2]/div[2]/div')\n",
    "                    sleep(5)\n",
    "\n",
    "                    # main_df = main_df.append(df, ignore_index=True)\n",
    "                print(\"surfshark's total campaigns are: {}\".format(len(pr_camps)))\n",
    "                pr_camps['source'] = 'surfshark'\n",
    "                pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace('[',''))\n",
    "                pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(']',''))\n",
    "                pr_camps['Link'] = pr_camps['Link'].map(lambda x: str(x).replace(\"'\",''))\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    return  pr_camps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Link</th>\n",
       "      <th>Source</th>\n",
       "      <th>Published Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global Data Breach Map</td>\n",
       "      <td>https://surfshark.com/research/data-breach-mon...</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Internet Shutdown Tracker</td>\n",
       "      <td>https://surfshark.com/research/internet-censor...</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Government Surveillance Report</td>\n",
       "      <td>https://surfshark.com/user-data-surveillance-r...</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Vulnerability Thermometer</td>\n",
       "      <td>https://surfshark.com/research/data-breach-impact</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How people see their privacy in 2022</td>\n",
       "      <td>https://surfshark.com/attitude-on-privacy</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data breach statistics 2022 Q1</td>\n",
       "      <td>https://surfshark.com/blog/data-breach-statist...</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data breach statistics by country in 2021</td>\n",
       "      <td>https://surfshark.com/blog/data-breach-statist...</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The data flows: How private are popular period...</td>\n",
       "      <td>https://surfshark.com/blog/period-track-app-da...</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cybersecurity in Ukraine and other former Sovi...</td>\n",
       "      <td>https://surfshark.com/blog/cybersecurity-ukrai...</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Children and online risks: global statistics</td>\n",
       "      <td>https://surfshark.com/research/cybersecurity-f...</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The most data-hungry ride-hailing and taxi apps</td>\n",
       "      <td>https://surfshark.com/blog/ride-hailing-taxi-a...</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which dating app wants your data the most?</td>\n",
       "      <td>https://surfshark.com/blog/dating-tracking-app</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What happens with leaked data?</td>\n",
       "      <td>https://surfshark.com/visualizing-data-breaches</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digital Quality of Life Index 2021</td>\n",
       "      <td>https://surfshark.com/dql2021</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private information in data brokers’ hands</td>\n",
       "      <td>https://surfshark.com/incogni</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data-hungry apps</td>\n",
       "      <td>https://surfshark.com/apps-that-track-you</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malware-ridden searches</td>\n",
       "      <td>https://surfshark.com/malware-ridden-searches</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reimagining 5 cybersecurity threats as horror ...</td>\n",
       "      <td>https://surfshark.com/digital-nightmares</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The estimated cost of the most expensive data ...</td>\n",
       "      <td>https://surfshark.com/cost-of-data-breaches</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regulating the web</td>\n",
       "      <td>https://surfshark.com/google-removed-content</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sites that are tracking your every move on...</td>\n",
       "      <td>https://surfshark.com/whos-tracking-you</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Employee surveillance report</td>\n",
       "      <td>https://surfshark.com/employee-surveillance</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Social media censorship statistics 2021</td>\n",
       "      <td>https://surfshark.com/blog/social-media-censor...</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The worst internet in the world is the least a...</td>\n",
       "      <td>https://surfshark.com/blog/worlds-worst-intern...</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global ad-blocking map</td>\n",
       "      <td>https://surfshark.com/global-ad-blocking</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cheating in games</td>\n",
       "      <td>https://surfshark.com/hacking-wins</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Surveillance cities</td>\n",
       "      <td>https://surfshark.com/surveillance-cities</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drone privacy laws</td>\n",
       "      <td>https://surfshark.com/drone-privacy-laws</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facial recognition world map</td>\n",
       "      <td>https://surfshark.com/facial-recognition-map</td>\n",
       "      <td>https://surfshark.com/research</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0                             Global Data Breach Map   \n",
       "0                          Internet Shutdown Tracker   \n",
       "0                     Government Surveillance Report   \n",
       "0                     Data Vulnerability Thermometer   \n",
       "0               How people see their privacy in 2022   \n",
       "0                     Data breach statistics 2022 Q1   \n",
       "0          Data breach statistics by country in 2021   \n",
       "0  The data flows: How private are popular period...   \n",
       "0  Cybersecurity in Ukraine and other former Sovi...   \n",
       "0       Children and online risks: global statistics   \n",
       "0    The most data-hungry ride-hailing and taxi apps   \n",
       "0         Which dating app wants your data the most?   \n",
       "0                     What happens with leaked data?   \n",
       "0                 Digital Quality of Life Index 2021   \n",
       "0         Private information in data brokers’ hands   \n",
       "0                                   Data-hungry apps   \n",
       "0                            Malware-ridden searches   \n",
       "0  Reimagining 5 cybersecurity threats as horror ...   \n",
       "0  The estimated cost of the most expensive data ...   \n",
       "0                                 Regulating the web   \n",
       "0  The sites that are tracking your every move on...   \n",
       "0                       Employee surveillance report   \n",
       "0            Social media censorship statistics 2021   \n",
       "0  The worst internet in the world is the least a...   \n",
       "0                             Global ad-blocking map   \n",
       "0                                  Cheating in games   \n",
       "0                                Surveillance cities   \n",
       "0                                 Drone privacy laws   \n",
       "0                       Facial recognition world map   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://surfshark.com/research/data-breach-mon...   \n",
       "0  https://surfshark.com/research/internet-censor...   \n",
       "0  https://surfshark.com/user-data-surveillance-r...   \n",
       "0  https://surfshark.com/research/data-breach-impact   \n",
       "0          https://surfshark.com/attitude-on-privacy   \n",
       "0  https://surfshark.com/blog/data-breach-statist...   \n",
       "0  https://surfshark.com/blog/data-breach-statist...   \n",
       "0  https://surfshark.com/blog/period-track-app-da...   \n",
       "0  https://surfshark.com/blog/cybersecurity-ukrai...   \n",
       "0  https://surfshark.com/research/cybersecurity-f...   \n",
       "0  https://surfshark.com/blog/ride-hailing-taxi-a...   \n",
       "0     https://surfshark.com/blog/dating-tracking-app   \n",
       "0    https://surfshark.com/visualizing-data-breaches   \n",
       "0                      https://surfshark.com/dql2021   \n",
       "0                      https://surfshark.com/incogni   \n",
       "0          https://surfshark.com/apps-that-track-you   \n",
       "0      https://surfshark.com/malware-ridden-searches   \n",
       "0           https://surfshark.com/digital-nightmares   \n",
       "0        https://surfshark.com/cost-of-data-breaches   \n",
       "0       https://surfshark.com/google-removed-content   \n",
       "0            https://surfshark.com/whos-tracking-you   \n",
       "0        https://surfshark.com/employee-surveillance   \n",
       "0  https://surfshark.com/blog/social-media-censor...   \n",
       "0  https://surfshark.com/blog/worlds-worst-intern...   \n",
       "0           https://surfshark.com/global-ad-blocking   \n",
       "0                 https://surfshark.com/hacking-wins   \n",
       "0          https://surfshark.com/surveillance-cities   \n",
       "0           https://surfshark.com/drone-privacy-laws   \n",
       "0       https://surfshark.com/facial-recognition-map   \n",
       "\n",
       "                           Source Published Date  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  \n",
       "0  https://surfshark.com/research    unavailable  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surfshark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stltraining\n",
    "\n",
    "def stltraining():\n",
    "    pr_camps = {}\n",
    "    for client_link in seedlist_client['client_link']:\n",
    "        if 'stl-training' in client_link:\n",
    "            try:\n",
    "                driver.get(client_link)\n",
    "                waiting_until_full(delay, '//*[@id=\"beststl_maincontent\"]/div[2]/section/div')\n",
    "                digital_pr = driver.find_element(By.XPATH, '//*[@id=\"beststl_maincontent\"]/div[2]/section/div')\n",
    "                lists = digital_pr.find_elements(By.TAG_NAME,'a')\n",
    "                links = list({lists[i].get_attribute('href') for i in range(len(lists))})\n",
    "                names = [lists[i].text for i in range(len(lists)) if lists[i].text != '']\n",
    "                pr_camps = {names[i]: links[i] for i in range(len(links))}\n",
    "                print(\"stltraining's total campaigns are: {}\".format(len(pr_camps)))\n",
    "                df = pd.DataFrame(list(pr_camps.items()),columns=['Name','Links'])\n",
    "                df['Source'] = 'https://www.stl-training.co.uk/sharing/'\n",
    "                df['Published Date'] = 'unavailable'\n",
    "                df['Links'] = df['Links'].map(lambda x: str(x).replace('[',''))\n",
    "                df['Links'] = df['Links'].map(lambda x: str(x).replace(']',''))\n",
    "                df['Links'] = df['Links'].map(lambda x: str(x).replace(\"'\",''))\n",
    "                df = df.iloc[2:,:]\n",
    "            except Exception as e:\n",
    "                continue \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stltraining's total campaigns are: 101\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Links</th>\n",
       "      <th>Source</th>\n",
       "      <th>Published Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>► Power BI Overview [Video]</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/13-how-...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>► What do I do with my feet when presenting? [...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/how-to-...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>► How do I keep good eye contact when presenti...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/techniq...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>► What is good video call etiquette? [Video]</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/the-gro...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>► Professional Development Virtual Classroom S...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/how-to-...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A well-trained I.T. team: Your company's secre...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/how-to-...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The History of Microsoft</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/excel-a...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>What's in and what's out in Office 2013?</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/14-exce...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Just How Big Is Microsoft? - Microsoft trainin...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/futurep...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>The History of Microsoft Office - Advanced Cou...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/extreme...</td>\n",
       "      <td>https://www.stl-training.co.uk/sharing/</td>\n",
       "      <td>unavailable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name  \\\n",
       "2                          ► Power BI Overview [Video]   \n",
       "3    ► What do I do with my feet when presenting? [...   \n",
       "4    ► How do I keep good eye contact when presenti...   \n",
       "5         ► What is good video call etiquette? [Video]   \n",
       "6    ► Professional Development Virtual Classroom S...   \n",
       "..                                                 ...   \n",
       "96   A well-trained I.T. team: Your company's secre...   \n",
       "97                            The History of Microsoft   \n",
       "98            What's in and what's out in Office 2013?   \n",
       "99   Just How Big Is Microsoft? - Microsoft trainin...   \n",
       "100  The History of Microsoft Office - Advanced Cou...   \n",
       "\n",
       "                                                 Links  \\\n",
       "2    https://www.stl-training.co.uk/sharing/13-how-...   \n",
       "3    https://www.stl-training.co.uk/sharing/how-to-...   \n",
       "4    https://www.stl-training.co.uk/sharing/techniq...   \n",
       "5    https://www.stl-training.co.uk/sharing/the-gro...   \n",
       "6    https://www.stl-training.co.uk/sharing/how-to-...   \n",
       "..                                                 ...   \n",
       "96   https://www.stl-training.co.uk/sharing/how-to-...   \n",
       "97   https://www.stl-training.co.uk/sharing/excel-a...   \n",
       "98   https://www.stl-training.co.uk/sharing/14-exce...   \n",
       "99   https://www.stl-training.co.uk/sharing/futurep...   \n",
       "100  https://www.stl-training.co.uk/sharing/extreme...   \n",
       "\n",
       "                                      Source Published Date  \n",
       "2    https://www.stl-training.co.uk/sharing/    unavailable  \n",
       "3    https://www.stl-training.co.uk/sharing/    unavailable  \n",
       "4    https://www.stl-training.co.uk/sharing/    unavailable  \n",
       "5    https://www.stl-training.co.uk/sharing/    unavailable  \n",
       "6    https://www.stl-training.co.uk/sharing/    unavailable  \n",
       "..                                       ...            ...  \n",
       "96   https://www.stl-training.co.uk/sharing/    unavailable  \n",
       "97   https://www.stl-training.co.uk/sharing/    unavailable  \n",
       "98   https://www.stl-training.co.uk/sharing/    unavailable  \n",
       "99   https://www.stl-training.co.uk/sharing/    unavailable  \n",
       "100  https://www.stl-training.co.uk/sharing/    unavailable  \n",
       "\n",
       "[99 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stltraining()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adhoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20916\\4241941079.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r'D:\\TKMedia\\chromedriver_win32-chromedriver.exe')\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r'D:\\TKMedia\\chromedriver_win32-chromedriver.exe')\n",
    "driver.set_page_load_timeout(20)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://defiyield.app/rekt-database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"pushable\"]/div/main/section/div[4]/div[2]/div[170]/div[1]/div[1]/div/a/span\"}\n  (Session info: chrome=110.0.5481.78)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00E437D3]\n\t(No symbol) [0x00DD8B81]\n\t(No symbol) [0x00CDB36D]\n\t(No symbol) [0x00D0D382]\n\t(No symbol) [0x00D0D4BB]\n\t(No symbol) [0x00D43302]\n\t(No symbol) [0x00D2B464]\n\t(No symbol) [0x00D41215]\n\t(No symbol) [0x00D2B216]\n\t(No symbol) [0x00D00D97]\n\t(No symbol) [0x00D0253D]\n\tGetHandleVerifier [0x010BABF2+2510930]\n\tGetHandleVerifier [0x010E8EC1+2700065]\n\tGetHandleVerifier [0x010EC86C+2714828]\n\tGetHandleVerifier [0x00EF3480+645344]\n\t(No symbol) [0x00DE0FD2]\n\t(No symbol) [0x00DE6C68]\n\t(No symbol) [0x00DE6D4B]\n\t(No symbol) [0x00DF0D6B]\n\tBaseThreadInitThunk [0x76AE7D69+25]\n\tRtlInitializeExceptionChain [0x775ABB9B+107]\n\tRtlClearBits [0x775ABB1F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [49], line 4\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     project \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39;49mfind_element(By\u001b[39m.\u001b[39;49mXPATH, \u001b[39m'\u001b[39;49m\u001b[39m//*[@id=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpushable\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m]/div/main/section/div[4]/div[2]/div[\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m]/div[1]/div[1]/div/a/span\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(i))\u001b[39m.\u001b[39mtext\n\u001b[0;32m      5\u001b[0m     chain \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mfind_element(By\u001b[39m.\u001b[39mXPATH,\u001b[39m'\u001b[39m\u001b[39m//*[@id=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpushable\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]/div/main/section/div[4]/div[2]/div[\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m]/div[1]/div[2]\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(i))\u001b[39m.\u001b[39mtext\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:861\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    859\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m[name=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m value\n\u001b[1;32m--> 861\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mFIND_ELEMENT, {\u001b[39m\"\u001b[39;49m\u001b[39musing\u001b[39;49m\u001b[39m\"\u001b[39;49m: by, \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m: value})[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:444\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 444\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    445\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:249\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"pushable\"]/div/main/section/div[4]/div[2]/div[170]/div[1]/div[1]/div/a/span\"}\n  (Session info: chrome=110.0.5481.78)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00E437D3]\n\t(No symbol) [0x00DD8B81]\n\t(No symbol) [0x00CDB36D]\n\t(No symbol) [0x00D0D382]\n\t(No symbol) [0x00D0D4BB]\n\t(No symbol) [0x00D43302]\n\t(No symbol) [0x00D2B464]\n\t(No symbol) [0x00D41215]\n\t(No symbol) [0x00D2B216]\n\t(No symbol) [0x00D00D97]\n\t(No symbol) [0x00D0253D]\n\tGetHandleVerifier [0x010BABF2+2510930]\n\tGetHandleVerifier [0x010E8EC1+2700065]\n\tGetHandleVerifier [0x010EC86C+2714828]\n\tGetHandleVerifier [0x00EF3480+645344]\n\t(No symbol) [0x00DE0FD2]\n\t(No symbol) [0x00DE6C68]\n\t(No symbol) [0x00DE6D4B]\n\t(No symbol) [0x00DF0D6B]\n\tBaseThreadInitThunk [0x76AE7D69+25]\n\tRtlInitializeExceptionChain [0x775ABB9B+107]\n\tRtlClearBits [0x775ABB1F+191]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [49], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m     final \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([final, pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_records([{\u001b[39m'\u001b[39m\u001b[39mProject\u001b[39m\u001b[39m'\u001b[39m: project, \u001b[39m'\u001b[39m\u001b[39mChain\u001b[39m\u001b[39m'\u001b[39m: chain, \u001b[39m'\u001b[39m\u001b[39mCategory\u001b[39m\u001b[39m'\u001b[39m: category, \u001b[39m'\u001b[39m\u001b[39mIssue\u001b[39m\u001b[39m'\u001b[39m: issue, \u001b[39m'\u001b[39m\u001b[39mValue Lost\u001b[39m\u001b[39m'\u001b[39m: value_lost, \u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m: date}])])\n\u001b[0;32m     11\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m---> 12\u001b[0m     project \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39;49mfind_element(By\u001b[39m.\u001b[39;49mXPATH, \u001b[39m'\u001b[39;49m\u001b[39m//*[@id=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpushable\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m]/div/main/section/div[4]/div[2]/div[\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m]/div[1]/div[1]/div/a/span\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(i))\u001b[39m.\u001b[39mtext\n\u001b[0;32m     13\u001b[0m     chain \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mfind_element(By\u001b[39m.\u001b[39mXPATH,\u001b[39m'\u001b[39m\u001b[39m//*[@id=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpushable\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]/div/main/section/div[4]/div[2]/div[\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m]/div[1]/div[2]\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(i))\u001b[39m.\u001b[39mtext\n\u001b[0;32m     14\u001b[0m     category \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mfind_element(By\u001b[39m.\u001b[39mXPATH,\u001b[39m'\u001b[39m\u001b[39m//*[@id=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpushable\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]/div/main/section/div[4]/div[2]/div[\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m]/div[1]/div[3]\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(i))\u001b[39m.\u001b[39mtext\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:861\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    858\u001b[0m     by \u001b[39m=\u001b[39m By\u001b[39m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    859\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m[name=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m value\n\u001b[1;32m--> 861\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mFIND_ELEMENT, {\u001b[39m\"\u001b[39;49m\u001b[39musing\u001b[39;49m\u001b[39m\"\u001b[39;49m: by, \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m: value})[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:444\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    442\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 444\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    445\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    446\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:249\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    247\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    248\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"pushable\"]/div/main/section/div[4]/div[2]/div[170]/div[1]/div[1]/div/a/span\"}\n  (Session info: chrome=110.0.5481.78)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00E437D3]\n\t(No symbol) [0x00DD8B81]\n\t(No symbol) [0x00CDB36D]\n\t(No symbol) [0x00D0D382]\n\t(No symbol) [0x00D0D4BB]\n\t(No symbol) [0x00D43302]\n\t(No symbol) [0x00D2B464]\n\t(No symbol) [0x00D41215]\n\t(No symbol) [0x00D2B216]\n\t(No symbol) [0x00D00D97]\n\t(No symbol) [0x00D0253D]\n\tGetHandleVerifier [0x010BABF2+2510930]\n\tGetHandleVerifier [0x010E8EC1+2700065]\n\tGetHandleVerifier [0x010EC86C+2714828]\n\tGetHandleVerifier [0x00EF3480+645344]\n\t(No symbol) [0x00DE0FD2]\n\t(No symbol) [0x00DE6C68]\n\t(No symbol) [0x00DE6D4B]\n\t(No symbol) [0x00DF0D6B]\n\tBaseThreadInitThunk [0x76AE7D69+25]\n\tRtlInitializeExceptionChain [0x775ABB9B+107]\n\tRtlClearBits [0x775ABB1F+191]\n"
     ]
    }
   ],
   "source": [
    "final = pd.DataFrame(columns=['Project', 'Chain', 'Category', 'Issue', 'Value Lost', 'Date'])\n",
    "for i in range(1,201):\n",
    "    try:\n",
    "        project = driver.find_element(By.XPATH, '//*[@id=\"pushable\"]/div/main/section/div[4]/div[2]/div[{}]/div[1]/div[1]/div/a/span'.format(i)).text\n",
    "        chain = driver.find_element(By.XPATH,'//*[@id=\"pushable\"]/div/main/section/div[4]/div[2]/div[{}]/div[1]/div[2]'.format(i)).text\n",
    "        category = driver.find_element(By.XPATH,'//*[@id=\"pushable\"]/div/main/section/div[4]/div[2]/div[{}]/div[1]/div[3]'.format(i)).text\n",
    "        issue = driver.find_element(By.XPATH,'//*[@id=\"pushable\"]/div/main/section/div[4]/div[2]/div[{}]/div[1]/div[4]/span'.format(i)).text\n",
    "        value_lost = driver.find_element(By.XPATH,'//*[@id=\"pushable\"]/div/main/section/div[4]/div[2]/div[{}]/div[1]/div[5]/span'.format(i)).text\n",
    "        date = driver.find_element(By.XPATH,'//*[@id=\"pushable\"]/div/main/section/div[4]/div[2]/div[{}]/div[1]/div[6]'.format(i)).text\n",
    "        final = pd.concat([final, pd.DataFrame.from_records([{'Project': project, 'Chain': chain, 'Category': category, 'Issue': issue, 'Value Lost': value_lost, 'Date': date}])])\n",
    "    except Exception as e:\n",
    "        project = driver.find_element(By.XPATH, '//*[@id=\"pushable\"]/div/main/section/div[4]/div[2]/div[{}]/div[1]/div[1]/div/a/span'.format(i)).text\n",
    "        chain = driver.find_element(By.XPATH,'//*[@id=\"pushable\"]/div/main/section/div[4]/div[2]/div[{}]/div[1]/div[2]'.format(i)).text\n",
    "        category = driver.find_element(By.XPATH,'//*[@id=\"pushable\"]/div/main/section/div[4]/div[2]/div[{}]/div[1]/div[3]'.format(i)).text\n",
    "        issue = driver.find_element(By.XPATH,'//*[@id=\"pushable\"]/div/main/section/div[4]/div[2]/div[{}]/div[1]/div[4]/span'.format(i)).text\n",
    "        value_lost = 'missing'\n",
    "        date = driver.find_element(By.XPATH,'//*[@id=\"pushable\"]/div/main/section/div[4]/div[2]/div[{}]/div[1]/div[6]'.format(i)).text\n",
    "        final = pd.concat([final, pd.DataFrame.from_records([{'Project': project, 'Chain': chain, 'Category': category, 'Issue': issue, 'Value Lost': value_lost, 'Date': date}])])\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72b2382ece9768098284d92bbc69d35954e75b60d1e25897d1389c232f4796f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
